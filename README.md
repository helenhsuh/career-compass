# Career Compass: AI-Assisted Career Pivot Reasoning Tool

Career Compass is a human-centered AI project designed to help individuals navigate complex career transitions with clarity and structure. The tool blends counseling-informed reasoning with foundational machine learning concepts to help users understand role alignment, transferable skills, and long-term career fit.

This repository reflects the full design and architecture of the project, including data preparation planning, feature engineering reasoning, baseline modeling approaches, evaluation strategies, and iterative experimentation. While no real dataset was used, the project is structured to support real development in the future.

---

## ğŸŒŸ Project Purpose

Career transitions are overwhelming. Job descriptions are inconsistent, skills are hard to compare, and people often lack access to personalized guidance. Career Compass aims to:

- Provide structured, accessible support for career pivots  
- Identify alignment between user backgrounds and potential roles  
- Surface transferable skills and realistic next-step pathways  
- Model trade-offs across skills, salary, location, and constraints  
- Demonstrate foundational ML reasoning and problem-solving  

---

## ğŸ§  Problem Definition

People need a way to understand which roles align with their skills, values, constraints, and long-term goals. Career Compass is designed to:

- Standardize role information  
- Represent user profiles and job descriptions in comparable formats  
- Rank roles based on alignment and user-defined priorities  
- Provide interpretable, human-centered recommendations  

---

## ğŸ—ï¸ Repository Structure

career-compass/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Unprocessed job descriptions, skills, taxonomies
â”‚   â”œâ”€â”€ interim/              # Cleaned but not yet structured
â”‚   â””â”€â”€ processed/            # Final structured data ready for modeling
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_design.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering_baselines.ipynb
â”‚   â”œâ”€â”€ 03_embeddings_exploration.ipynb
â”‚   â”œâ”€â”€ 04_similarity_and_ranking.ipynb
â”‚   â””â”€â”€ 05_evaluation_strategy.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ data_design.py            # Schema definition and data planning
â”‚   â”‚   â””â”€â”€ preprocessing.py          # Text normalization and cleaning utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ tfidf_features.py         # Baseline TFâ€‘IDF vectorization
â”‚   â”‚   â””â”€â”€ embedding_features.py     # Embedding feature scaffolding
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ baseline_similarity.py    # Cosine similarity ranking
â”‚   â”‚   â””â”€â”€ embedding_similarity.py   # Embeddingâ€‘based similarity design
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics.py                # Semantic similarity and clustering metrics
â”‚   â”‚   â””â”€â”€ human_review.py           # Humanâ€‘inâ€‘theâ€‘loop evaluation design
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ helpers.py                # Shared helper functions
â”‚       â””â”€â”€ config.py                 # Configuration settings
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ project_overview.md
â”‚   â”œâ”€â”€ data_design.md
â”‚   â”œâ”€â”€ feature_engineering.md
â”‚   â”œâ”€â”€ modeling_approach.md
â”‚   â”œâ”€â”€ evaluation_plan.md
â”‚   â”œâ”€â”€ limitations_and_future_work.md
â”‚   â””â”€â”€ ethical_considerations.md
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_similarity.py
â”‚   â””â”€â”€ test_embeddings.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ CONTRIBUTING.md
â””â”€â”€ README.md


## How to Navigate This Repo

Career Compass is organized to reflect the full reasoning and architecture behind the project, even without a real dataset. If you're exploring the repository, hereâ€™s the best way to understand how everything fits together:

### 1. Start with the `docs/` folder  
This is the conceptual foundation of the project. It includes:
- project_overview.md â€“ purpose and vision  
- data_design.md â€“ schema planning and data assumptions  
- feature_engineering.md â€“ baseline and embedding reasoning  
- modeling_approach.md â€“ similarity and ranking design  
- evaluation_plan.md â€“ hybrid evaluation strategy  
- limitations_and_future_work.md â€“ constraints and next steps  
- ethical_considerations.md â€“ fairness, transparency, and user agency  

### 2. Explore the `notebooks/` directory  
These notebooks walk through the reasoning process step by step:
- data design  
- baseline feature engineering  
- embedding exploration  
- similarity scoring  
- evaluation planning  

### 3. Review the `src/` directory  
This is the code scaffolding for future development:
- data/ â€“ preprocessing and schema logic  
- features/ â€“ TFâ€‘IDF and embedding feature modules  
- models/ â€“ baseline and embedding similarity modules  
- evaluation/ â€“ metrics and humanâ€‘review design  
- utils/ â€“ shared helpers and configuration  

### 4. Check the `tests/` folder  
These starter tests reflect engineering best practices.

### 5. Look at `requirements.txt` and `CONTRIBUTING.md`  
These outline dependencies and collaboration guidelines.

This structure is designed to demonstrate engineering thinking, ML reasoning, and humanâ€‘centered design, while keeping the project ready for future development.
---

## ğŸ”§ Technical Foundations Demonstrated

### **Data Thinking**
- Schema design  
- Planning for normalization, deduplication, labeling  
- Understanding what â€œclean dataâ€ means in ML contexts  

### **Feature Engineering**
- TFâ€‘IDF baseline  
- Cosine similarity  
- Transformer-based embedding design  
- Trade-offs between interpretability and performance  

### **Modeling Reasoning**
- Why baselines matter  
- When embeddings are appropriate  
- How to compare models  
- How to evaluate without labels  

### **Evaluation Strategy**
- Hybrid metrics + human review  
- Clustering coherence  
- Counseling-informed interpretability  

---

## ğŸ§ª Challenges & How They Were Overcome

- **No dataset available** â†’ Designed full pipeline with synthetic examples  
- **Knowledge gaps in embeddings** â†’ Used documentation, small experiments, and AI assistants  
- **Unclear evaluation without labels** â†’ Designed hybrid evaluation strategy  
- **AI assistants giving incorrect code** â†’ Verified, discarded, and corrected through reasoning  

---

## ğŸ¤– Use of AI Coding Assistants

AI tools were used to:
- Scaffold code structure  
- Debug syntax issues  
- Visualize vector similarity concepts  

AI tools were *not* blindly trusted.  
Incorrect outputs were discarded and replaced with documented reasoning.

---

## ğŸš€ Future Work

- Collect real datasets  
- Build an API for role matching  
- Add user feedback loops  
- Integrate salary/location trade-off modeling  
- Create a dashboard for skill-gap analysis  

---

## ğŸ§­ Why This Project Matters

Career Compass reflects:
- Human-centered design  
- Ethical reasoning  
- Data-driven thinking  
- ML conceptual understanding  
- Problem decomposition  
- Responsible use of AI  

It is intentionally designed to grow into a real product while demonstrating the engineering mindset required for the REACH apprenticeship.
